{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xhxuciedu/CS175/blob/master/pytorch-tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7FKQCFzXDnGH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import torch \n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q_w92gMaP6N1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check Package Versions"
      ]
    },
    {
      "metadata": {
        "id": "uYr2YRtWPkel",
        "colab_type": "code",
        "outputId": "fbe5ccf8-2839-4dbc-ea99-0246e48dfcfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "print('__Python VERSION:', sys.version)\n",
        "print('__PyTorch VERSION:', torch.__version__)\n",
        "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
        "print('__Number CUDA Devices:', torch.cuda.device_count())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__Python VERSION: 3.6.7 (default, Oct 22 2018, 11:32:17) \n",
            "[GCC 8.2.0]\n",
            "__PyTorch VERSION: 1.0.1.post2\n",
            "__CUDNN VERSION: 7402\n",
            "__Number CUDA Devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Eq_6EZ0QM23",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### PyTorch\n",
        "What is PyTorch?\n",
        "\n",
        "It’s a Python based scientific computing package targeted at two sets of audiences:\n",
        "\n",
        "* A replacement for numpy to use the power of GPUs\n",
        "* a deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "cSa2TTQfQ3nS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tensors\n",
        "\n",
        "Tensors are similar to numpy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n",
        "\n",
        "\n",
        "Construct a 5x3 matrix, uninitialized"
      ]
    },
    {
      "metadata": {
        "id": "xTW9C9zVRLWy",
        "colab_type": "code",
        "outputId": "639363a3-0d7f-4b1c-96de-2b5db58e6097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5.2516e-36, 0.0000e+00, 3.7835e-44],\n",
            "        [0.0000e+00,        nan, 1.4013e-45],\n",
            "        [1.3733e-14, 6.4069e+02, 4.3066e+21],\n",
            "        [1.1824e+22, 4.3066e+21, 6.3828e+28],\n",
            "        [3.8016e-39, 2.0893e+20, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i74pPBySRRDZ",
        "colab_type": "code",
        "outputId": "20615421-59ab-43ee-8fa9-82e5ad1a37e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# get its size\n",
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3.3493e-01, 7.8662e-01, 7.4520e-01],\n",
            "        [4.4676e-01,        nan, 9.9131e-01],\n",
            "        [8.0851e-01, 6.4072e+02, 4.3066e+21],\n",
            "        [1.1824e+22, 4.3066e+21, 6.3828e+28],\n",
            "        [4.2417e-01, 2.0893e+20, 5.9098e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O0xeSB-3Rd1L",
        "colab_type": "code",
        "outputId": "4faa6804-187a-42d9-979e-e5606e512ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# Addition: in-place\n",
        "y.add_(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.3493e-01, 7.8662e-01, 7.4520e-01],\n",
              "        [4.4676e-01,        nan, 9.9131e-01],\n",
              "        [8.0851e-01, 6.4072e+02, 4.3066e+21],\n",
              "        [1.1824e+22, 4.3066e+21, 6.3828e+28],\n",
              "        [4.2417e-01, 2.0893e+20, 5.9098e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "QagJi5H9YT_M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create tensors"
      ]
    },
    {
      "metadata": {
        "id": "zF881O3lYfwc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# random\n",
        "v = torch.rand(2, 3)            # Initialize with random number (uniform distribution)\n",
        "v = torch.randn(2, 3)           # With normal distribution (SD=1, mean=0)\n",
        "v = torch.randperm(4)   \n",
        "\n",
        "# ones\n",
        "eye = torch.eye(3)              # Create an identity 3x3 tensor\n",
        "v = torch.ones(10)              # A tensor of size 10 containing all ones\n",
        "v = torch.ones(2, 1, 2, 1)      # Size 2x1x2x1\n",
        "v = torch.ones_like(eye)        # A tensor with same shape as eye. Fill it with 1.\n",
        "\n",
        "# zeros\n",
        "v = torch.zeros(10) \n",
        "\n",
        "# range of values\n",
        "v = torch.arange(5)             # similar to range(5) but creating a Tensor\n",
        "v = torch.arange(0, 5, step=1)  # Size 5. Similar to range(0, 5, 1)\n",
        "\n",
        "# linear or log scale\n",
        "v = torch.linspace(1, 10, steps=10) # Create a Tensor with 10 linear points for (1, 10) inclusively\n",
        "v = torch.logspace(start=-10, end=10, steps=5) # Size 5: 1.0e-10 1.0e-05 1.0e+00, 1.0e+05, 1.0e+10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j0_vX6QFbP9r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dot product, component-wide product, matrix multiplication, "
      ]
    },
    {
      "metadata": {
        "id": "Hbf5A2rTYonK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dot product of 2 tensors\n",
        "r = torch.dot(torch.Tensor([4, 2]), torch.Tensor([3, 1])) # 14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F-AZEEfEYosW",
        "colab_type": "code",
        "outputId": "87244745-3a0f-4bac-b8e0-70d8e2883b04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# component-wise product\n",
        "torch.Tensor([4, 2])* torch.Tensor([3, 1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.,  2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "bnfFZpz4a0JG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Matrix x Matrix\n",
        "# Size 2x4\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 4)\n",
        "r = torch.mm(mat1, mat2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9fNQ8Aw-ahBH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Batch Matrix x Matrix\n",
        "# Size 10x3x5\n",
        "batch1 = torch.randn(10, 3, 4)\n",
        "batch2 = torch.randn(10, 4, 5)\n",
        "r = torch.bmm(batch1, batch2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zygHVhSba0eN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Squeeze and unsqueeze"
      ]
    },
    {
      "metadata": {
        "id": "vylLWkFfaicW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = torch.ones(2,1,2,1) # Size 2x1x2x1\n",
        "r = torch.squeeze(t)     # Size 2x2\n",
        "r = torch.squeeze(t, 1)  # Squeeze dimension 1: Size 2x2x1\n",
        "\n",
        "# Un-squeeze a dimension\n",
        "x = torch.Tensor([1, 2, 3])\n",
        "r = torch.unsqueeze(x, 0)       # Size: 1x3\n",
        "r = torch.unsqueeze(x, 1)       # Size: 3x1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6gEsNF3a-26",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Transpose\n"
      ]
    },
    {
      "metadata": {
        "id": "TwCePtvPa_hO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e86f11f5-f08b-4170-ee6a-5642bb71157e"
      },
      "cell_type": "code",
      "source": [
        "# Transpose dim 0 and 1\n",
        "v = torch.randn(3,2)\n",
        "r = torch.transpose(v, 0, 1)\n",
        "print(r.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G6wj7JQJRna5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Numpy Bridge\n",
        "Converting a torch Tensor to a numpy array and vice versa is a breeze.\n",
        "\n",
        "The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.\n",
        "\n",
        "Converting torch Tensor to numpy Array"
      ]
    },
    {
      "metadata": {
        "id": "M-V3P-KeOdFY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a numpy array.\n",
        "x = np.array([[1, 2], [3, 4]])\n",
        "\n",
        "# Convert the numpy array to a torch tensor.\n",
        "y = torch.from_numpy(x)\n",
        "\n",
        "# Convert the torch tensor to a numpy array.\n",
        "z = y.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DrxFA9zrOhcw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Conversion\n",
        "a = np.array([1, 2, 3])\n",
        "v = torch.from_numpy(a)         # Convert a numpy array to a Tensor\n",
        "\n",
        "b = v.numpy()                   # Tensor to numpy\n",
        "b[1] = -1                       # Numpy and Tensor share the same memory\n",
        "assert(a[1] == b[1])            # Change Numpy will also change the Tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PkrFAPSzYDLa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reshape tensor"
      ]
    },
    {
      "metadata": {
        "id": "TVJAK82AYB78",
        "colab_type": "code",
        "outputId": "007f7582-81a4-42f4-fc78-df3af6cf9222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "### Tensor resizing\n",
        "x = torch.randn(2, 3)            # Size 2x3\n",
        "y = x.view(6)                    # Resize x to size 6\n",
        "z = x.view(-1, 2)                # Size 3x2\n",
        "print(y.shape, z.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6]) torch.Size([3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cfoEcojSYTra",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJnuUJgeSH5S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###CUDA Tensors\n",
        "\n",
        "All the Tensors on the CPU except a CharTensor support converting to NumPy and back.\n",
        "\n",
        "\n",
        "Tensors can be moved onto GPU using the .cuda function."
      ]
    },
    {
      "metadata": {
        "id": "IPUVPxqbSP_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "\n",
        "x = torch.rand(3,2)\n",
        "y = torch.rand(3,2)\n",
        "if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "    y = y.cuda()\n",
        "    x + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fUYQkqCUSiRT",
        "colab_type": "code",
        "outputId": "5887c7d4-16d1-46fc-cea0-ab5fd86219bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "x"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5451, 0.3420],\n",
              "        [0.1150, 0.9795],\n",
              "        [0.5707, 0.6249]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "N20kEqktSQKm",
        "colab_type": "code",
        "outputId": "bf64dcd4-a141-4db3-ad4b-a94b6426936b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "y"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7567, 0.9499],\n",
              "        [0.1165, 0.3316],\n",
              "        [0.7169, 0.1606]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "1mS3kiy9UNoR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Autograd: automatic differentiation\n",
        "\n",
        "Central to all neural networks in PyTorch is autograd, a core torch package for automatic differentiation. \n",
        "\n",
        "\n",
        "The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n",
        "\n",
        "Let us see this in more simple terms with some examples."
      ]
    },
    {
      "metadata": {
        "id": "PmxgzX_6U4rn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create an variable\n",
        "x = torch.ones((2,2), requires_grad=True)\n",
        "\n",
        "# Do an operation of variable:\n",
        "y = x + 2\n",
        "\n",
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "out = z.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jdNxo2rxU4zr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Gradients\n",
        "# ---------\n",
        "# let's backprop now\n",
        "# ``out.backward()`` is equivalent to doing ``out.backward(torch.Tensor([1.0]))``\n",
        "out.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNK-RRBmU43f",
        "colab_type": "code",
        "outputId": "9e37cbba-140c-4218-a958-a5fcc5675bfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "###############################################################\n",
        "# print gradients d(out)/dx\n",
        "#\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VUDiTPCeWGlU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You should have got a matrix of ``4.5``. Let’s call the ``out`` *Variable* $o$.\n",
        "We have that: $o = \\frac{1}{4}\\sum_i z_i$, \n",
        "$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$\n",
        "\n",
        "Therefore,\n",
        "$$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$$ hence\n",
        "$$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$$"
      ]
    },
    {
      "metadata": {
        "id": "bKL_ex-DWs_L",
        "colab_type": "code",
        "outputId": "0ac440c6-1d5b-42c5-b43c-3d05cab2a3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# You can do many crazy things with autograd!\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  -19.0446, -1363.2463,   615.8981], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vmSVgbJNWyqu",
        "colab_type": "code",
        "outputId": "fefb44da-f63e-472a-fdeb-d865d760742d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
        "y.backward(gradients)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mQ5oVt1kFv6N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic autograd example 1 "
      ]
    },
    {
      "metadata": {
        "id": "Lx-5ce4DE2y-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create tensors.\n",
        "x = torch.tensor(1., requires_grad=True)\n",
        "w = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(3., requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mcy6p4nSE5Yt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build a computational graph.\n",
        "y = w * x + b    # y = 2 * x + 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gzfF4EDBGyJB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compute gradients.\n",
        "y.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3hIZDh1GrJn",
        "colab_type": "code",
        "outputId": "6644d264-f509-443e-e605-ed7872f84a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Print out the gradients.\n",
        "print(x.grad)    # x.grad = 2 \n",
        "print(w.grad)    # w.grad = 1 \n",
        "print(b.grad)    # b.grad = 1 "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iiS-D364E6JC",
        "colab_type": "code",
        "outputId": "3b63df8f-2f17-46a3-d691-036c4d3b86a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y.detach().numpy()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(5., dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "ahapqf3VF8Fn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic autograd example 2  "
      ]
    },
    {
      "metadata": {
        "id": "lgah0xn0GCxA",
        "colab_type": "code",
        "outputId": "6a0fa5ff-3df4-475e-afa9-657c0a6f4969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Create tensors of shape (10, 3) and (10, 2).\n",
        "x = torch.randn(10, 3)\n",
        "y = torch.randn(10, 2)\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 3]) torch.Size([10, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oiQkdoJXGLeJ",
        "colab_type": "code",
        "outputId": "cfaca1b4-18cc-4f38-e5d8-b77cff3ad8a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# Build a fully connected layer.\n",
        "linear = nn.Linear(3, 2)\n",
        "print ('w: ', linear.weight)\n",
        "print ('b: ', linear.bias)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:  Parameter containing:\n",
            "tensor([[ 0.2923, -0.3317,  0.4008],\n",
            "        [ 0.5509,  0.5610,  0.3034]], requires_grad=True)\n",
            "b:  Parameter containing:\n",
            "tensor([0.1883, 0.2975], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IvOuGobUG_c4",
        "colab_type": "code",
        "outputId": "6e553523-cfeb-4334-a296-845b03169ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "loss = torch.sum((linear(x)-y)**2)/y.shape[0]\n",
        "print('loss: ', loss.data.numpy())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:  3.5154366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-Jg-jZqxIswR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UIJ9YkofIszl",
        "colab_type": "code",
        "outputId": "a14f9462-0c5e-4582-ba51-a117c4342958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print('w grad: ', linear.weight.grad)\n",
        "print('b grad: ', linear.bias.grad)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w grad:  tensor([[ 1.4770, -0.6500,  0.5289],\n",
            "        [ 0.5974,  0.6427,  0.3403]])\n",
            "b grad:  tensor([ 1.1086, -0.3205])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vPtT7MCXJJsj",
        "colab_type": "code",
        "outputId": "d04d5a97-e004-4e41-dae4-b5042e87c871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# check grad\n",
        "print('w grad:', (linear(x)-y).transpose(0,1).mm(x)/y.shape[0]*2)\n",
        "print('b grad:', 2*torch.mean(linear(x)-y, dim=0))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w grad: tensor([[ 1.4770, -0.6500,  0.5289],\n",
            "        [ 0.5974,  0.6427,  0.3403]], grad_fn=<MulBackward0>)\n",
            "b grad: tensor([ 1.1086, -0.3205], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yy7Cv9ugMN0K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###. Basic autograd example 3"
      ]
    },
    {
      "metadata": {
        "id": "hon-LU88MN6L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create tensors of shape (10, 3) and (10, 2).\n",
        "x = torch.randn(10, 3)\n",
        "y = torch.randn(10, 2)\n",
        "linear = nn.Linear(3, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ltmT6QfoFMal",
        "colab_type": "code",
        "outputId": "3edb5dbc-b95a-4a90-d1da-346eac735305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# Build loss function and optimizer.\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
        "\n",
        "# Forward pass.\n",
        "pred = linear(x)\n",
        "\n",
        "# Compute loss.\n",
        "loss = criterion(pred, y)\n",
        "print('loss: ', loss.item())\n",
        "\n",
        "# Backward pass.\n",
        "loss.backward()\n",
        "\n",
        "# Print out the gradients.\n",
        "print ('dL/dw: ', linear.weight.grad) \n",
        "print ('dL/db: ', linear.bias.grad)\n",
        "\n",
        "# 1-step gradient descent.\n",
        "optimizer.step()\n",
        "\n",
        "# You can also perform gradient descent at the low level.\n",
        "# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
        "# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
        "\n",
        "# Print out the loss after 1-step gradient descent.\n",
        "pred = linear(x)\n",
        "loss = criterion(pred, y)\n",
        "print('loss after 1 step optimization: ', loss.item())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:  2.252901792526245\n",
            "dL/dw:  tensor([[-0.3655,  0.6044, -1.0335],\n",
            "        [ 0.5968,  0.1730,  0.0765]])\n",
            "dL/db:  tensor([ 0.8729, -0.3719])\n",
            "loss after 1 step optimization:  2.224485397338867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YC-xoV6kPmlm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}